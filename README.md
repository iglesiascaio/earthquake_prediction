# Earthquake AI: Predicting Maximum Earthquake Magnitude in California

[![Research Report](https://img.shields.io/badge/Research-Report%20PDF-blue)](Research_Report-4.pdf)
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

## ğŸ“‹ Project Overview

This repository implements a **hybrid modeling framework** for forecasting the maximum earthquake magnitude in the Los Angeles region over the next 30 days. The methodology integrates two complementary approaches:

1. **Seismic Waveform-Based Model**: Leverages continuous waveform recordings and deep representation learning using the SeisLM foundation model
2. **Event-Based Probabilistic Model**: Grounded in Gutenberg-Richter relations and historical seismicity rates

The system combines these approaches to enhance predictive robustness and accuracy, providing early warning capabilities for seismic risk assessment.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           EARTHQUAKE PREDICTION PIPELINE                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   WAVEFORM      â”‚    â”‚    TABULAR      â”‚    â”‚     PREDICTION          â”‚  â”‚
â”‚  â”‚   PIPELINE      â”‚    â”‚    PIPELINE     â”‚    â”‚     SYSTEM              â”‚  â”‚
â”‚  â”‚                 â”‚    â”‚                 â”‚    â”‚                         â”‚  â”‚
â”‚  â”‚ â€¢ 30-day 3-comp â”‚    â”‚ â€¢ Earthquake    â”‚    â”‚ â€¢ Multi-class           â”‚  â”‚
â”‚  â”‚   waveforms     â”‚    â”‚   catalogs      â”‚    â”‚   classification        â”‚  â”‚
â”‚  â”‚ â€¢ SeisLM        â”‚    â”‚ â€¢ Rolling       â”‚    â”‚ â€¢ Magnitude bins        â”‚  â”‚
â”‚  â”‚   embeddings    â”‚    â”‚   features      â”‚    â”‚ â€¢ 30-day horizon        â”‚  â”‚
â”‚  â”‚ â€¢ LSTM/Toto     â”‚    â”‚ â€¢ ETAS, B-valuesâ”‚    â”‚ â€¢ Hybrid fusion         â”‚  â”‚
â”‚  â”‚   aggregation   â”‚    â”‚ â€¢ Energy stats  â”‚    â”‚                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                       â”‚                       â”‚                 â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                   â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    FEATURE FUSION & MODELING                        â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚  Gradient   â”‚  â”‚    GNN      â”‚  â”‚      Evaluation &           â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  Boosting   â”‚  â”‚  (GAT/SAGE) â”‚  â”‚      Deployment             â”‚  â”‚    â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚                             â”‚  â”‚    â”‚
â”‚  â”‚  â”‚ â€¢ LightGBM  â”‚  â”‚ â€¢ Spatial   â”‚  â”‚ â€¢ Multi-metric              â”‚  â”‚    â”‚
â”‚  â”‚  â”‚ â€¢ Tabular   â”‚  â”‚   awareness â”‚  â”‚   assessment                â”‚  â”‚    â”‚
â”‚  â”‚  â”‚ â€¢ Efficient â”‚  â”‚ â€¢ Station   â”‚  â”‚ â€¢ ROC-AUC, Accuracy         â”‚  â”‚    â”‚
â”‚  â”‚  â”‚             â”‚  â”‚   networks  â”‚  â”‚ â€¢ Confusion matrices        â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”˜
```

## ğŸ¯ Research Objectives

- **Primary Goal**: Predict maximum earthquake magnitude in LA region within 30 days
- **Classification**: 9 magnitude classes (M<1.0 to Mâ‰¥8.0)
- **Input**: Continuous seismic waveforms + historical earthquake catalogs
- **Output**: Discrete magnitude risk assessment

## ğŸ“ Repository Structure

```
earthquake-ai/
â”œâ”€â”€ ğŸ“Š 01_Seismic_Wave_Data_Prediction/     # Main SeisLM + Toto pipeline
â”‚   â”œâ”€â”€ seisLM_main.py                      # Main orchestration script
â”‚   â”œâ”€â”€ seisLM_main.sh                      # SLURM job submission script
â”‚   â”œâ”€â”€ seisLM_main_new.ipynb               # Jupyter notebook version
â”‚   â”œâ”€â”€ config.yaml                         # Configuration parameters
â”‚   â”œâ”€â”€ TESTING.ipynb                       # Comprehensive testing notebook
â”‚   â”œâ”€â”€ merge_waveform_streams.sh           # Shell script for waveform merging
â”‚   â”œâ”€â”€ merge_waveform_streams.py           # Python script for waveform merging
â”‚   â”œâ”€â”€ 02_Functions/                       # Core model implementations
â”‚   â”‚   â”œâ”€â”€ Model_Trainer.py               # Training orchestration
â”‚   â”‚   â”œâ”€â”€ Model_Evaluator.py             # Evaluation framework
â”‚   â”‚   â”œâ”€â”€ Dataset_creation.py            # Waveform dataset creation
â”‚   â”‚   â”œâ”€â”€ SeisLM_train.py                # SeisLM model definitions
â”‚   â”‚   â”œâ”€â”€ __init__.py                    # Package initialization
â”‚   â”‚   â”œâ”€â”€ 00_Archive/                    # Archived/legacy implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ Dataset_creation_old.py   # Previous dataset creation version
â”‚   â”‚   â”‚   â”œâ”€â”€ SeisLM_train.py           # Previous SeisLM training version
â”‚   â”‚   â”‚   â””â”€â”€ Seismic_event_data_preprocessing.py # Legacy preprocessing
â”‚   â”‚   â””â”€â”€ seisLM/                        # SeisLM foundation model
â”‚   â”œâ”€â”€ 01_Data/                           # Data storage and processing
â”‚   â”‚   â”œâ”€â”€ 01_Seismic_Wave_Data/          # Processed waveform streams
â”‚   â”‚   â”‚   â”œâ”€â”€ 2020/                      # 2020 waveform data
â”‚   â”‚   â”‚   â”œâ”€â”€ 2021/                      # 2021 waveform data
â”‚   â”‚   â”‚   â”œâ”€â”€ 2022/                      # 2022 waveform data
â”‚   â”‚   â”‚   â”œâ”€â”€ 2023/                      # 2023 waveform data
â”‚   â”‚   â”‚   â”œâ”€â”€ 2024/                      # 2024 waveform data
â”‚   â”‚   â”‚   â”œâ”€â”€ Combined_Processed_Streams_30_new/ # 30-day combined streams
â”‚   â”‚   â”‚   â”œâ”€â”€ Combined_Processed_Streams_30_new_2025_07_28/ # 30-day streams (more data)
â”‚   â”‚   â”‚   â””â”€â”€ Combined_Processed_Streams_50_new_2025_07_28/ # 50-day combined streams (more data)
â”‚   â”‚   â””â”€â”€ 02_Seismic_Event_Data/         # Earthquake catalogs
â”‚   â”‚       â”œâ”€â”€ earthquake_features.parquet # Main earthquake features 
â”‚   â”‚       â”œâ”€â”€ curr_earthquake_features.parquet # Current earthquake features
â”‚   â”‚       â”œâ”€â”€ earthquake_events_2020_2025_Caio.parquet # Caio's earthquake dataset 
â”‚   â”œâ”€â”€ 03_Results/                         # Model outputs and checkpoints
â”‚   â”‚   â”œâ”€â”€ seislm_toto_*/                 # Toto-based model results 
â”‚   â”‚   â”œâ”€â”€ seislm_lstm_*/                 # LSTM-based model results 
â”‚   â”‚   â””â”€â”€ [Timestamped experiment directories] # All experiment outputs
â”‚   â”œâ”€â”€ 04_Trace_Preprocessing/             # Waveform preprocessing pipeline
â”‚   â”‚   â”œâ”€â”€ process_waveforms.ipynb         # Main preprocessing notebook
â”‚   â”‚   â”œâ”€â”€ merge_waveform_streams.py       # Waveform merging utility
â”‚   â”‚   â”œâ”€â”€ 01_Data/                       # Raw waveform data
â”‚   â”‚   â”œâ”€â”€ 02_Logs/                       # Processing logs
â”‚   â”‚   â””â”€â”€ 03_Waveform_Analysis/          # Station-specific analysis notebooks
â”‚   â”‚       â”œâ”€â”€ PASC_waveform_analysis.ipynb    # PASC station analysis
â”‚   â”‚       â”œâ”€â”€ MAN_waveform_analysis.ipynb     # MAN station analysis
â”‚   â”‚       â””â”€â”€ [Additional station notebooks]  # Other station analyses
â”‚   â”œâ”€â”€ toto_models/                        # Toto model checkpoints
â”‚
â”œâ”€â”€ ğŸ§  02_Full_Model/                       # GNN-based spatial modeling
â”‚   â”œâ”€â”€ src/                                # Source code directory
â”‚   â”‚   â”œâ”€â”€ model/                          # GNN model implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ gnn_experiment.py           # Main GNN experiment
â”‚   â”‚   â”‚   â”œâ”€â”€ gnn_hyperparameter_tuning.py # 75-architecture tuning
â”‚   â”‚   â”‚   â”œâ”€â”€ matching_experiment.py      # Feature matching experiments
â”‚   â”‚   â”‚   â”œâ”€â”€ model_train.py              # GNN training utilities
â”‚   â”‚   â”‚   â””â”€â”€ utils/                      # GNN utilities and helpers
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py             # Utils package initialization
â”‚   â”‚   â”‚       â”œâ”€â”€ evaluation.py           # Evaluation utilities
â”‚   â”‚   â”‚       â”œâ”€â”€ gnn_helper.py           # GNN-specific helper functions
â”‚   â”‚   â”‚       â””â”€â”€ load_data.py            # Data loading utilities
â”‚   â”‚   â””â”€â”€ data_prep/                      # Data preparation pipeline
â”‚   â”‚       â”œâ”€â”€ __init__.py                 # Data prep package initialization
â”‚   â”‚       â”œâ”€â”€ raw/                        # Raw data download utilities
â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py             # Raw package initialization
â”‚   â”‚       â”‚   â”œâ”€â”€ download_data.py        # Earthquake catalog download
â”‚   â”‚       â”‚   â””â”€â”€ download_data.sh        # Download script for SLURM
â”‚   â”‚       â””â”€â”€ features/                   # Feature engineering pipeline
â”‚   â”‚           â”œâ”€â”€ __init__.py             # Features package initialization
â”‚   â”‚           â””â”€â”€ create_features.py      # Seismological feature creation
â”‚   â”œâ”€â”€ config/                             # Configuration files
â”‚   â”‚   â”œâ”€â”€ 00-download-config.yaml         # Data download configuration
â”‚   â”‚   â””â”€â”€ 10-features-config.yaml         # Feature engineering configuration
â”‚   â”œâ”€â”€ notebooks/                          # Jupyter notebooks
â”‚   â”‚   â”œâ”€â”€ data_exploration.ipynb          # Data exploration and analysis
â”‚   â”‚   â”œâ”€â”€ model_exploration.ipynb         # Model architecture exploration
â”‚   â”‚   â””â”€â”€ next_steps.ipynb                # Future development planning
â”‚   â”œâ”€â”€ data/                               # Processed feature data
â”‚   â”‚   â”œâ”€â”€ features/                       # Engineered features
â”‚   â”‚   â”‚   â””â”€â”€ earthquake_features.parquet # Main feature dataset (5.5MB)
â”‚   â”‚   â””â”€â”€ raw/                            # Raw earthquake data
â”‚   â”œâ”€â”€ results/                             # GNN experiment results
â”‚   â”œâ”€â”€ activate                             # Environment activation script
â”‚   â”œâ”€â”€ gnn_experiment.sh                   # SLURM job for GNN experiments
â”‚   â”œâ”€â”€ gnn_hyperparameter_tuning.sh        # SLURM job for hyperparameter tuning
â”‚   â”œâ”€â”€ model_train_experiment.sh            # SLURM job for model training
â”‚   â””â”€â”€ matching_experiment.sh               # SLURM job for matching experiments
â”‚
â”œâ”€â”€ ğŸš€ toto/                                # Toto foundation model source
â”œâ”€â”€ ğŸ“š Toto-Open-Base-1.0/                 # Pre-trained Toto weights
â”œâ”€â”€ ğŸ“„ Research_Report-4.pdf                # Comprehensive research documentation
â”œâ”€â”€ ğŸ“‹ requirements.txt                     # Python dependencies and versions
â”œâ”€â”€ ğŸ“– README.md                            # This documentation file
â”œâ”€â”€ ğŸ“ .gitignore                           # Git ignore patterns
```

## ğŸ”¬ Key Components

### 1. Seismic Waveform Processing (`01_Seismic_Wave_Data_Prediction/`)

#### **Data Sources**
- **SCEDC**: Southern California Earthquake Data Center via AWS
- **Coverage**: 25+ broadband stations, 3 components (BHZ, BHE, BHN)
- **Format**: MiniSEED files with continuous recordings


#### **Waveform Preprocessing Pipeline**
- **`process_waveforms.ipynb`**: Main preprocessing workflow for all daily waveforms of stations
- **`merge_waveform_streams.py`**: Utility for combining daily waveform files to multiple day waveforms
- **Station-Specific Analysis**: Individual notebooks for each seismic station
- **Data Quality Control**: Gap detection, zero-filling, and validation
- **Multi-Day Streams**: Configurable windowing for temporal analysis

#### **SeisLM Integration**
- **Foundation Model**: Pre-trained SeisLM with frozen backbone (130MB checkpoint)
- **Embeddings**: 256-dimensional representations per time window
- **Aggregation**: Multiple temporal aggregation strategies:
  - **LSTM + Attention**: Sequential processing with learned weighting
  - **Toto Head**: Transformer-based foundation model integration

#### **Embedding Generation and Storage**
- **`seisLM_main.py`**: Creates SeisLM embeddings from seismic waveforms
- **Embedding Storage**: Saves embeddings in `03_Results/` folder for reuse
- **Performance Evaluation**: Tests embeddings alone for magnitude prediction
- **Baseline Results**: Establishes performance benchmark using only waveform embeddings
- **Reusable Features**: Embeddings can be loaded for different downstream tasks



### 2. Tabular Feature Engineering (`02_Full_Model/`)

#### **Data Preparation Pipeline**
- **`download_data.py`**: Automated earthquake catalog download from FDSN services
- **`download_data.sh`**: SLURM-compatible download script for batch processing
- **`create_features.py`**: Comprehensive feature engineering from raw catalogs
- **Multi-station Support**: Handles 50+ stations with automated processing

#### **Seismological Features**
- **Basic Statistics**: Daily max/min/mean magnitude, event counts
- **Energy Measures**: Gutenberg-Richter energy scaling
- **Recurrence Features**: Time since last event by magnitude class
- **Advanced Indicators**: B-values, T-values, magnitude deficits
- **ETAS Modeling**: Aftershock intensity and clustering

#### **Feature Aggregation**
```python
# Daily station-level features
- Rolling windows (7-30 days)
- Spatial proximity filtering (50km radius)
- Magnitude-dependent calculations
- Temporal lag features for context
```

### 3. Graph Neural Network Modeling (`02_Full_Model/src/model/`)

#### **Architecture Variants**
- **StationGNN**: GraphSAGE-based spatial modeling
- **StationGAT**: Graph Attention Network with learned neighbor importance
- **Spatial Context**: 100km radius for station connectivity

#### **Hyperparameter Tuning**
- **25 Model Configurations**: Hidden sizes, layers, attention heads
- **3 Embedding Scenarios**: Feature availability optimization
- **75 Total Experiments**: Systematic architecture evaluation

#### **Exploration and Analysis Tools**
- **`data_exploration.ipynb`**: Comprehensive data analysis and visualization
- **`model_exploration.ipynb`**: Model architecture experimentation
- **`next_steps.ipynb`**: Future development planning and roadmap
- **Configuration Files**: YAML-based setup for data download and feature engineering

### 4. Multi-Modal Fusion

#### **Feature Combination Strategies**
1. **Waveform Only**: SeisLM embeddings + temporal aggregation
   - **Baseline Performance**: Embeddings alone achieve significant magnitude prediction accuracy
   - **Stored Results**: Embeddings saved in results folder for analysis and reuse
   - **Temporal Context**: LSTM/Toto aggregation captures sequential patterns
2. **Tabular Only**: Engineered seismological features
3. **Hybrid Approach**: Combined waveform + tabular features

#### **Modeling Approaches**
- **Gradient Boosting**: LightGBM for efficient tabular learning
- **Graph Neural Networks**: Spatial-aware station modeling
- **Ensemble Methods**: Combining multiple approaches

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Clone the repository
git clone <repository-url>
cd earthquake-ai

# Activate conda environment
conda activate toto-310

# Install dependencies from requirements.txt
pip install -r requirements.txt
```

### 2. Configuration

Edit `01_Seismic_Wave_Data_Prediction/config.yaml`:

```yaml
# Data paths
paths:
  combined_stream_dir: "/path/to/processed/waveforms"
  earthquake_parquet: "/path/to/earthquake/catalog"
  output_dir: "/path/to/results"

# Model configuration
model:
  model_type: "seislm"           # Options: "seislm", "scattering"
  aggregation_type: "toto"        # Options: "toto", "lstm", "transformer"
  toto:
    regime: "partial"             # Options: "head", "partial", "full"
    pretrained_name: "/path/to/toto/model"

# Training parameters
training:
  num_epochs: 10
  batch_size: 4
  learning_rate: 0.0005
```

### 3. Data Preparation (Optional)

#### **Download Seismic Waveforms**
```python
import os
import boto3
from botocore import UNSIGNED
from botocore.config import Config
from obspy import UTCDateTime

# Configuration
bucket_name = "scedc-pds"
station = "JVA"  # Example station
channels = ["BHZ", "BHE", "BHN"]
year = 2020      # Example year
base_dir = f"01_Data/01_Seismic_Wave_Data/{station}_BB_{year}_s3"

# S3 client (unsigned access)
s3 = boto3.resource("s3", config=Config(signature_version=UNSIGNED))
bucket = s3.Bucket(bucket_name)

# Loop through each day and channel
start_day = UTCDateTime(f"{year}-01-01")
end_day = UTCDateTime(f"{year}-12-31")
day = start_day

while day <= end_day:
    jday = f"{day.julday:03d}"
    date_str = day.strftime("%Y-%m-%d")

    for channel in channels:
        # Construct S3 key and local path
        key = f"continuous_waveforms/{year}/{year}_{jday}/CI{station}__{channel}___{year}{jday}.ms"
        channel_dir = os.path.join(base_dir, channel)
        os.makedirs(channel_dir, exist_ok=True)
        filename = f"{station}_{channel}_{date_str}.mseed"
        local_path = os.path.join(channel_dir, filename)

        try:
            bucket.download_file(key, local_path)
            print(f"âœ… Saved: {local_path}")
        except Exception as e:
            print(f"âŒ Failed: {key} â€” {e}")

    day += 86400  # move to next day

print("ğŸ‰ All files downloaded and saved in structured folders.")
```

**Important**: After downloading, you must process the waveforms before training:

1. **Preprocess Waveforms**: Use `process_waveforms.ipynb` to clean and prepare the data
2. **Merge Streams**: Use `merge_waveform_streams.py` to combine daily files into longer segments (e.g., 30-day streams)
3. **Quality Control**: Detect gaps, fill missing data, and validate stream integrity
4. **Then Train**: Only after preprocessing can you run the training pipeline

#### **Download Earthquake Catalogs**
```bash
# Download earthquake catalogs and create features
cd 02_Full_Model
python src/data_prep/raw/download_data.py
python src/data_prep/features/create_features.py

# Or use SLURM scripts for large datasets
sbatch src/data_prep/raw/download_data.sh
```

### 4. Run Training

```bash
# SeisLM + Toto pipeline
cd 01_Seismic_Wave_Data_Prediction
python seisLM_main.py --mode train

# Or submit as SLURM job
sbatch seisLM_main.sh
```

**Training Workflow**:
1. **Generates embeddings** from seismic waveforms using SeisLM
2. **Saves embeddings** in `03_Results/` folder for reuse
3. **Evaluates baseline performance** using embeddings alone for magnitude prediction
4. **Trains full model** with temporal aggregation (LSTM/Toto)

# GNN hyperparameter tuning
cd 02_Full_Model
sbatch gnn_hyperparameter_tuning.sh

# Other GNN experiments
sbatch gnn_experiment.sh           # Single GNN experiment
sbatch model_train_experiment.sh   # Model training experiment
sbatch matching_experiment.sh      # Feature matching experiment
```

**HPC Integration**: All major experiments include SLURM job scripts for cluster execution:
- **`seisLM_main.sh`**: Main SeisLM + Toto training pipeline
- **`gnn_hyperparameter_tuning.sh`**: 75-architecture systematic evaluation
- **`gnn_experiment.sh`**: Single GNN architecture testing
- **`model_train_experiment.sh`**: Model training experiments
- **`matching_experiment.sh`**: Feature matching and comparison studies

### 5. Evaluate Results

```bash
# Model evaluation
python seisLM_main.py --mode evaluate

# View GNN results
cd 02_Full_Model/results
python -c "import json; print(json.dumps(json.load(open('final_results.json')), indent=2))"
```

## ğŸ“Š Current Performance

### **Preliminary Results** (Limited Data, Top Features)
- **Baseline (No Embeddings)**: ROC-AUC: 0.5825, Accuracy: 0.6436
- **With SeisLM Embeddings**: ROC-AUC: 0.6583 (+0.0758), Accuracy: 0.6277
- **Best Performance**: Classes 3-4 (M 3.0-5.0) with AUC 0.77-0.74

### **Data Availability**
- **Complete Coverage**: PASC, SDG, SYN stations (2020-2024)
- **Partial Coverage**: Multiple stations with missing years
- **Limited Data**: Many stations missing 2020-2022 data

### **Data Organization**
- **Waveform Data**: 5 years of continuous recordings (2020-2024)
- **Combined Streams**: 30-day and 50-day processed waveform segments
- **Earthquake Catalogs**: Multiple parquet datasets with varying completeness
- **Feature Datasets**: Engineered seismological features (5.5MB+)
- **Model Checkpoints**: Pre-trained SeisLM model (130MB)
- **Experiment Results**: 90+ timestamped experiment directories

## ğŸ”— Related Work

- **SeisLM**: [Foundation Model for Seismic Waveforms](https://arxiv.org/abs/2410.15765)
- **Toto**: [Time Series Optimized Transformer](https://arxiv.org/abs/2505.14766)
- **SCEDC**: [Southern California Earthquake Data Center](https://scedc.caltech.edu/)

## ğŸ“ Contact

- **Maximilian Knuth**: mknuth@mit.edu
- **Caio Iglesias**: caiopigl@mit.edu

