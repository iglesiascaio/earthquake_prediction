{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa70d83-565d-40b8-b1c9-c1d7a5589e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Scanning absolute directory: /home/gridsan/mknuth/01_Seismic_Wave_Data_Prediction/01_Data/01_Seismic_Wave_Data\n",
      "\n",
      "\n",
      "🗓️  Year 2020, Station SDD — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2020, Station IPT — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 170 / Expected 366 days\n",
      "    🚨 Missing 196 days\n",
      "    🔄 Checking channel BHN: Found 170 / Expected 366 days\n",
      "    🚨 Missing 196 days\n",
      "    🔄 Checking channel BHZ: Found 170 / Expected 366 days\n",
      "    🚨 Missing 196 days\n",
      "\n",
      "🗓️  Year 2020, Station CYP — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2020, Station BHP — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 366 days\n",
      "    🚨 Missing 1 days\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 366 days\n",
      "    🚨 Missing 1 days\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 366 days\n",
      "    🚨 Missing 1 days\n",
      "\n",
      "🗓️  Year 2020, Station EML — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 287 / Expected 366 days\n",
      "    🚨 Missing 79 days\n",
      "    🔄 Checking channel BHN: Found 287 / Expected 366 days\n",
      "    🚨 Missing 79 days\n",
      "    🔄 Checking channel BHZ: Found 287 / Expected 366 days\n",
      "    🚨 Missing 79 days\n",
      "\n",
      "🗓️  Year 2020, Station BTP — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 229 / Expected 366 days\n",
      "    🚨 Missing 137 days\n",
      "    🔄 Checking channel BHN: Found 229 / Expected 366 days\n",
      "    🚨 Missing 137 days\n",
      "    🔄 Checking channel BHZ: Found 229 / Expected 366 days\n",
      "    🚨 Missing 137 days\n",
      "\n",
      "🗓️  Year 2020, Station YUH2 — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2020, Station SYN — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2020, Station SES — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2020, Station GOR — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2020, Station DGR — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2020, Station HYS — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2020, Station WRC2 — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2020, Station SDG — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2020, Station PASC — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station CPO — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station SDD — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station BHZ — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station BRE — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station CYP — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station BHP — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 308 / Expected 366 days\n",
      "    🚨 Missing 58 days\n",
      "    🔄 Checking channel BHN: Found 308 / Expected 366 days\n",
      "    🚨 Missing 58 days\n",
      "    🔄 Checking channel BHZ: Found 308 / Expected 366 days\n",
      "    🚨 Missing 58 days\n",
      "\n",
      "🗓️  Year 2024, Station RRX — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station EML — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 262 / Expected 366 days\n",
      "    🚨 Missing 104 days\n",
      "\n",
      "🗓️  Year 2024, Station LAF — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 337 / Expected 366 days\n",
      "    🚨 Missing 29 days\n",
      "    🔄 Checking channel BHN: Found 337 / Expected 366 days\n",
      "    🚨 Missing 29 days\n",
      "    🔄 Checking channel BHZ: Found 338 / Expected 366 days\n",
      "    🚨 Missing 28 days\n",
      "\n",
      "🗓️  Year 2024, Station YUH2 — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station SYN — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station LVY — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 366 days\n",
      "    🚨 Missing 1 days\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 366 days\n",
      "    🚨 Missing 1 days\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 366 days\n",
      "    🚨 Missing 1 days\n",
      "\n",
      "🗓️  Year 2024, Station CRR — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station STG — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station BAI — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station ABL — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station FMO — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station GOR — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station DGR — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station HYS — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station AGM — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station SDG — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station MAN — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2024, Station DLA — expecting 366 days\n",
      "    🔄 Checking channel BHE: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 366 / Expected 366 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2022, Station SDD — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 363 / Expected 365 days\n",
      "    🚨 Missing 2 days\n",
      "    🔄 Checking channel BHN: Found 363 / Expected 365 days\n",
      "    🚨 Missing 2 days\n",
      "    🔄 Checking channel BHZ: Found 363 / Expected 365 days\n",
      "    🚨 Missing 2 days\n",
      "\n",
      "🗓️  Year 2022, Station BHP — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2022, Station RRX — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2022, Station EML — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2022, Station BTP — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2022, Station LAF — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2022, Station CRR — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2022, Station STG — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2022, Station SES — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2022, Station GOR — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 71 / Expected 365 days\n",
      "    🚨 Missing 294 days\n",
      "    🔄 Checking channel BHN: Found 71 / Expected 365 days\n",
      "    🚨 Missing 294 days\n",
      "    🔄 Checking channel BHZ: Found 71 / Expected 365 days\n",
      "    🚨 Missing 294 days\n",
      "\n",
      "🗓️  Year 2022, Station SDG — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2022, Station PASC — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2022, Station DLA — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 1 / Expected 365 days\n",
      "    🚨 Missing 364 days\n",
      "    🔄 Checking channel BHN: Found 1 / Expected 365 days\n",
      "    🚨 Missing 364 days\n",
      "    🔄 Checking channel BHZ: Found 1 / Expected 365 days\n",
      "    🚨 Missing 364 days\n",
      "\n",
      "🗓️  Year 2023, Station CPO — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station SDD — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station BRE — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station BHP — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station RRX — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station EML — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 174 / Expected 365 days\n",
      "    🚨 Missing 191 days\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station LAF — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station SYN — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station LVY — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station PTD — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station STG — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station BAI — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station ABL — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 0 / Expected 365 days\n",
      "    🚨 Missing 365 days\n",
      "    🔄 Checking channel BHN: Found 0 / Expected 365 days\n",
      "    🚨 Missing 365 days\n",
      "    🔄 Checking channel BHZ: Found 0 / Expected 365 days\n",
      "    🚨 Missing 365 days\n",
      "\n",
      "🗓️  Year 2023, Station SES — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station FMO — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station GOR — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station HYS — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station AGM — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station SDG — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station PASC — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station MAN — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2023, Station DLA — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 342 / Expected 365 days\n",
      "    🚨 Missing 23 days\n",
      "    🔄 Checking channel BHN: Found 342 / Expected 365 days\n",
      "    🚨 Missing 23 days\n",
      "    🔄 Checking channel BHZ: Found 342 / Expected 365 days\n",
      "    🚨 Missing 23 days\n",
      "\n",
      "🗓️  Year 2021, Station SDD — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 359 / Expected 365 days\n",
      "    🚨 Missing 6 days\n",
      "    🔄 Checking channel BHN: Found 359 / Expected 365 days\n",
      "    🚨 Missing 6 days\n",
      "    🔄 Checking channel BHZ: Found 359 / Expected 365 days\n",
      "    🚨 Missing 6 days\n",
      "\n",
      "🗓️  Year 2021, Station CWC — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 328 / Expected 365 days\n",
      "    🚨 Missing 37 days\n",
      "    🔄 Checking channel BHN: Found 327 / Expected 365 days\n",
      "    🚨 Missing 38 days\n",
      "    🔄 Checking channel BHZ: Found 328 / Expected 365 days\n",
      "    🚨 Missing 37 days\n",
      "\n",
      "🗓️  Year 2021, Station BRE — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 323 / Expected 365 days\n",
      "    🚨 Missing 42 days\n",
      "    🔄 Checking channel BHN: Found 323 / Expected 365 days\n",
      "    🚨 Missing 42 days\n",
      "    🔄 Checking channel BHZ: Found 323 / Expected 365 days\n",
      "    🚨 Missing 42 days\n",
      "\n",
      "🗓️  Year 2021, Station CYP — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2021, Station BHP — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2021, Station RRX — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2021, Station EML — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 313 / Expected 365 days\n",
      "    🚨 Missing 52 days\n",
      "    🔄 Checking channel BHN: Found 313 / Expected 365 days\n",
      "    🚨 Missing 52 days\n",
      "    🔄 Checking channel BHZ: Found 313 / Expected 365 days\n",
      "    🚨 Missing 52 days\n",
      "\n",
      "🗓️  Year 2021, Station LAF — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 301 / Expected 365 days\n",
      "    🚨 Missing 64 days\n",
      "    🔄 Checking channel BHN: Found 301 / Expected 365 days\n",
      "    🚨 Missing 64 days\n",
      "    🔄 Checking channel BHZ: Found 301 / Expected 365 days\n",
      "    🚨 Missing 64 days\n",
      "\n",
      "🗓️  Year 2021, Station SYN — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2021, Station STG — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2021, Station SES — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2021, Station GOR — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 360 / Expected 365 days\n",
      "    🚨 Missing 5 days\n",
      "    🔄 Checking channel BHN: Found 360 / Expected 365 days\n",
      "    🚨 Missing 5 days\n",
      "    🔄 Checking channel BHZ: Found 360 / Expected 365 days\n",
      "    🚨 Missing 5 days\n",
      "\n",
      "🗓️  Year 2021, Station DGR — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2021, Station HYS — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 340 / Expected 365 days\n",
      "    🚨 Missing 25 days\n",
      "    🔄 Checking channel BHN: Found 340 / Expected 365 days\n",
      "    🚨 Missing 25 days\n",
      "    🔄 Checking channel BHZ: Found 340 / Expected 365 days\n",
      "    🚨 Missing 25 days\n",
      "\n",
      "🗓️  Year 2021, Station WRC2 — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2021, Station SDG — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2021, Station PASC — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHN: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "    🔄 Checking channel BHZ: Found 365 / Expected 365 days\n",
      "    ✅ Complete\n",
      "\n",
      "🗓️  Year 2021, Station DLA — expecting 365 days\n",
      "    🔄 Checking channel BHE: Found 364 / Expected 365 days\n",
      "    🚨 Missing 1 days\n",
      "    🔄 Checking channel BHN: Found 364 / Expected 365 days\n",
      "    🚨 Missing 1 days\n",
      "    🔄 Checking channel BHZ: Found 364 / Expected 365 days\n",
      "    🚨 Missing 1 days\n",
      "\n",
      "Summary of Issues:\n",
      "🚨 2020 - IPT - BHE: 196 days missing.\n",
      "    Example missing dates: 2020-06-19, 2020-06-20, 2020-06-21, 2020-06-22, 2020-06-23 ...\n",
      "🚨 2020 - IPT - BHN: 196 days missing.\n",
      "    Example missing dates: 2020-06-19, 2020-06-20, 2020-06-21, 2020-06-22, 2020-06-23 ...\n",
      "🚨 2020 - IPT - BHZ: 196 days missing.\n",
      "    Example missing dates: 2020-06-19, 2020-06-20, 2020-06-21, 2020-06-22, 2020-06-23 ...\n",
      "🚨 2020 - BHP - BHE: 1 days missing.\n",
      "    Example missing dates: 2020-08-02 ...\n",
      "🚨 2020 - BHP - BHN: 1 days missing.\n",
      "    Example missing dates: 2020-08-02 ...\n",
      "🚨 2020 - BHP - BHZ: 1 days missing.\n",
      "    Example missing dates: 2020-08-02 ...\n",
      "🚨 2020 - EML - BHE: 79 days missing.\n",
      "    Example missing dates: 2020-03-16, 2020-03-17, 2020-03-18, 2020-03-19, 2020-03-20 ...\n",
      "🚨 2020 - EML - BHN: 79 days missing.\n",
      "    Example missing dates: 2020-03-16, 2020-03-17, 2020-03-18, 2020-03-19, 2020-03-20 ...\n",
      "🚨 2020 - EML - BHZ: 79 days missing.\n",
      "    Example missing dates: 2020-03-16, 2020-03-17, 2020-03-18, 2020-03-19, 2020-03-20 ...\n",
      "🚨 2020 - BTP - BHE: 137 days missing.\n",
      "    Example missing dates: 2020-08-17, 2020-08-18, 2020-08-19, 2020-08-20, 2020-08-21 ...\n",
      "🚨 2020 - BTP - BHN: 137 days missing.\n",
      "    Example missing dates: 2020-08-17, 2020-08-18, 2020-08-19, 2020-08-20, 2020-08-21 ...\n",
      "🚨 2020 - BTP - BHZ: 137 days missing.\n",
      "    Example missing dates: 2020-08-17, 2020-08-18, 2020-08-19, 2020-08-20, 2020-08-21 ...\n",
      "🚨 2024 - BHP - BHE: 58 days missing.\n",
      "    Example missing dates: 2024-04-12, 2024-11-05, 2024-11-06, 2024-11-07, 2024-11-08 ...\n",
      "🚨 2024 - BHP - BHN: 58 days missing.\n",
      "    Example missing dates: 2024-04-12, 2024-11-05, 2024-11-06, 2024-11-07, 2024-11-08 ...\n",
      "🚨 2024 - BHP - BHZ: 58 days missing.\n",
      "    Example missing dates: 2024-04-12, 2024-11-05, 2024-11-06, 2024-11-07, 2024-11-08 ...\n",
      "🚨 2024 - EML - BHZ: 104 days missing.\n",
      "    Example missing dates: 2024-09-18, 2024-09-20, 2024-09-21, 2024-09-22, 2024-09-23 ...\n",
      "🚨 2024 - LAF - BHE: 29 days missing.\n",
      "    Example missing dates: 2024-12-03, 2024-12-04, 2024-12-05, 2024-12-06, 2024-12-07 ...\n",
      "🚨 2024 - LAF - BHN: 29 days missing.\n",
      "    Example missing dates: 2024-12-03, 2024-12-04, 2024-12-05, 2024-12-06, 2024-12-07 ...\n",
      "🚨 2024 - LAF - BHZ: 28 days missing.\n",
      "    Example missing dates: 2024-12-04, 2024-12-05, 2024-12-06, 2024-12-07, 2024-12-08 ...\n",
      "🚨 2024 - LVY - BHE: 1 days missing.\n",
      "    Example missing dates: 2024-10-12 ...\n",
      "🚨 2024 - LVY - BHN: 1 days missing.\n",
      "    Example missing dates: 2024-10-12 ...\n",
      "🚨 2024 - LVY - BHZ: 1 days missing.\n",
      "    Example missing dates: 2024-10-12 ...\n",
      "🚨 2022 - SDD - BHE: 2 days missing.\n",
      "    Example missing dates: 2022-03-27, 2022-03-28 ...\n",
      "🚨 2022 - SDD - BHN: 2 days missing.\n",
      "    Example missing dates: 2022-03-27, 2022-03-28 ...\n",
      "🚨 2022 - SDD - BHZ: 2 days missing.\n",
      "    Example missing dates: 2022-03-27, 2022-03-28 ...\n",
      "🚨 2022 - GOR - BHE: 294 days missing.\n",
      "    Example missing dates: 2022-03-13, 2022-03-14, 2022-03-15, 2022-03-16, 2022-03-17 ...\n",
      "🚨 2022 - GOR - BHN: 294 days missing.\n",
      "    Example missing dates: 2022-03-13, 2022-03-14, 2022-03-15, 2022-03-16, 2022-03-17 ...\n",
      "🚨 2022 - GOR - BHZ: 294 days missing.\n",
      "    Example missing dates: 2022-03-13, 2022-03-14, 2022-03-15, 2022-03-16, 2022-03-17 ...\n",
      "🚨 2022 - DLA - BHE: 364 days missing.\n",
      "    Example missing dates: 2022-01-01, 2022-01-02, 2022-01-03, 2022-01-04, 2022-01-05 ...\n",
      "🚨 2022 - DLA - BHN: 364 days missing.\n",
      "    Example missing dates: 2022-01-01, 2022-01-02, 2022-01-03, 2022-01-04, 2022-01-05 ...\n",
      "🚨 2022 - DLA - BHZ: 364 days missing.\n",
      "    Example missing dates: 2022-01-01, 2022-01-02, 2022-01-03, 2022-01-04, 2022-01-05 ...\n",
      "🚨 2023 - EML - BHN: 191 days missing.\n",
      "    Example missing dates: 2023-06-24, 2023-06-25, 2023-06-26, 2023-06-27, 2023-06-28 ...\n",
      "🚨 2023 - ABL - BHE: 365 days missing.\n",
      "    Example missing dates: 2023-01-01, 2023-01-02, 2023-01-03, 2023-01-04, 2023-01-05 ...\n",
      "🚨 2023 - ABL - BHN: 365 days missing.\n",
      "    Example missing dates: 2023-01-01, 2023-01-02, 2023-01-03, 2023-01-04, 2023-01-05 ...\n",
      "🚨 2023 - ABL - BHZ: 365 days missing.\n",
      "    Example missing dates: 2023-01-01, 2023-01-02, 2023-01-03, 2023-01-04, 2023-01-05 ...\n",
      "🚨 2023 - DLA - BHE: 23 days missing.\n",
      "    Example missing dates: 2023-01-02, 2023-01-03, 2023-01-04, 2023-01-05, 2023-01-06 ...\n",
      "🚨 2023 - DLA - BHN: 23 days missing.\n",
      "    Example missing dates: 2023-01-02, 2023-01-03, 2023-01-04, 2023-01-05, 2023-01-06 ...\n",
      "🚨 2023 - DLA - BHZ: 23 days missing.\n",
      "    Example missing dates: 2023-01-02, 2023-01-03, 2023-01-04, 2023-01-05, 2023-01-06 ...\n",
      "🚨 2021 - SDD - BHE: 6 days missing.\n",
      "    Example missing dates: 2021-07-30, 2021-07-31, 2021-08-01, 2021-08-02, 2021-08-03 ...\n",
      "🚨 2021 - SDD - BHN: 6 days missing.\n",
      "    Example missing dates: 2021-07-30, 2021-07-31, 2021-08-01, 2021-08-02, 2021-08-03 ...\n",
      "🚨 2021 - SDD - BHZ: 6 days missing.\n",
      "    Example missing dates: 2021-07-30, 2021-07-31, 2021-08-01, 2021-08-02, 2021-08-03 ...\n",
      "🚨 2021 - CWC - BHE: 37 days missing.\n",
      "    Example missing dates: 2021-07-20, 2021-07-21, 2021-07-22, 2021-07-23, 2021-07-24 ...\n",
      "🚨 2021 - CWC - BHN: 38 days missing.\n",
      "    Example missing dates: 2021-07-20, 2021-07-21, 2021-07-22, 2021-07-23, 2021-07-24 ...\n",
      "🚨 2021 - CWC - BHZ: 37 days missing.\n",
      "    Example missing dates: 2021-07-20, 2021-07-21, 2021-07-22, 2021-07-23, 2021-07-24 ...\n",
      "🚨 2021 - BRE - BHE: 42 days missing.\n",
      "    Example missing dates: 2021-10-06, 2021-10-07, 2021-10-08, 2021-10-09, 2021-10-10 ...\n",
      "🚨 2021 - BRE - BHN: 42 days missing.\n",
      "    Example missing dates: 2021-10-06, 2021-10-07, 2021-10-08, 2021-10-09, 2021-10-10 ...\n",
      "🚨 2021 - BRE - BHZ: 42 days missing.\n",
      "    Example missing dates: 2021-10-06, 2021-10-07, 2021-10-08, 2021-10-09, 2021-10-10 ...\n",
      "🚨 2021 - EML - BHE: 52 days missing.\n",
      "    Example missing dates: 2021-07-05, 2021-07-06, 2021-07-07, 2021-07-08, 2021-07-09 ...\n",
      "🚨 2021 - EML - BHN: 52 days missing.\n",
      "    Example missing dates: 2021-07-05, 2021-07-06, 2021-07-07, 2021-07-08, 2021-07-09 ...\n",
      "🚨 2021 - EML - BHZ: 52 days missing.\n",
      "    Example missing dates: 2021-07-05, 2021-07-06, 2021-07-07, 2021-07-08, 2021-07-09 ...\n",
      "🚨 2021 - LAF - BHE: 64 days missing.\n",
      "    Example missing dates: 2021-01-20, 2021-01-21, 2021-01-22, 2021-01-23, 2021-01-24 ...\n",
      "🚨 2021 - LAF - BHN: 64 days missing.\n",
      "    Example missing dates: 2021-01-20, 2021-01-21, 2021-01-22, 2021-01-23, 2021-01-24 ...\n",
      "🚨 2021 - LAF - BHZ: 64 days missing.\n",
      "    Example missing dates: 2021-01-20, 2021-01-21, 2021-01-22, 2021-01-23, 2021-01-24 ...\n",
      "🚨 2021 - GOR - BHE: 5 days missing.\n",
      "    Example missing dates: 2021-06-27, 2021-06-28, 2021-06-29, 2021-06-30, 2021-07-01 ...\n",
      "🚨 2021 - GOR - BHN: 5 days missing.\n",
      "    Example missing dates: 2021-06-27, 2021-06-28, 2021-06-29, 2021-06-30, 2021-07-01 ...\n",
      "🚨 2021 - GOR - BHZ: 5 days missing.\n",
      "    Example missing dates: 2021-06-27, 2021-06-28, 2021-06-29, 2021-06-30, 2021-07-01 ...\n",
      "🚨 2021 - HYS - BHE: 25 days missing.\n",
      "    Example missing dates: 2021-02-25, 2021-02-26, 2021-02-27, 2021-02-28, 2021-03-01 ...\n",
      "🚨 2021 - HYS - BHN: 25 days missing.\n",
      "    Example missing dates: 2021-02-25, 2021-02-26, 2021-02-27, 2021-02-28, 2021-03-01 ...\n",
      "🚨 2021 - HYS - BHZ: 25 days missing.\n",
      "    Example missing dates: 2021-02-25, 2021-02-26, 2021-02-27, 2021-02-28, 2021-03-01 ...\n",
      "🚨 2021 - DLA - BHE: 1 days missing.\n",
      "    Example missing dates: 2021-12-31 ...\n",
      "🚨 2021 - DLA - BHN: 1 days missing.\n",
      "    Example missing dates: 2021-12-31 ...\n",
      "🚨 2021 - DLA - BHZ: 1 days missing.\n",
      "    Example missing dates: 2021-12-31 ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "root_dir = \"/home/gridsan/mknuth/01_Seismic_Wave_Data_Prediction/01_Data/01_Seismic_Wave_Data\"\n",
    "\n",
    "\n",
    "def expected_dates(year):\n",
    "    start_date = datetime.date(year, 1, 1)\n",
    "    end_date = datetime.date(year, 12, 31)\n",
    "    return set((start_date + datetime.timedelta(days=i)).strftime('%Y-%m-%d') \n",
    "               for i in range((end_date - start_date).days + 1))\n",
    "\n",
    "def validate_waveform_files(root_dir):\n",
    "    results = defaultdict(lambda: defaultdict(lambda: defaultdict(set)))\n",
    "    all_channels_found = defaultdict(set)\n",
    "    issues = []\n",
    "\n",
    "    print(f\"🔍 Scanning absolute directory: {root_dir}\\n\")\n",
    "    \n",
    "    for root, _, files in os.walk(root_dir):\n",
    "        abs_root = os.path.abspath(root)\n",
    "        parts = abs_root.replace(root_dir, \"\").strip(os.sep).split(os.sep)\n",
    "\n",
    "        #print(f\"📂 Exploring: {abs_root} | Depth: {len(parts)} | Parts: {parts}\")\n",
    "\n",
    "        if len(parts) != 3:\n",
    "            continue  # skip folders that are not year/station/channel\n",
    "        \n",
    "\n",
    "        year, station, channel = parts\n",
    "        all_channels_found[(year, station)].add(channel)\n",
    "\n",
    "        for file in files:\n",
    "            if file.endswith(\".mseed\") and not file.endswith(\"_processed.mseed\"):\n",
    "                try:\n",
    "                    date_str = file.split('_')[-1].replace('.mseed', '')\n",
    "                    results[year][station][channel].add(date_str)\n",
    "                    #print(f\"    📄 Found file: {file} (Date: {date_str})\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    ⚠️ Failed to parse file: {file}, Error: {e}\")\n",
    "\n",
    "    for (year, station), channels in all_channels_found.items():\n",
    "        year_int = int(year)\n",
    "        expected = expected_dates(year_int)\n",
    "        print(f\"\\n🗓️  Year {year}, Station {station} — expecting {len(expected)} days\")\n",
    "\n",
    "        for ch in [\"BHE\", \"BHN\", \"BHZ\"]:\n",
    "            found_dates = results[year][station].get(ch, set())\n",
    "            print(f\"    🔄 Checking channel {ch}: Found {len(found_dates)} / Expected {len(expected)} days\")\n",
    "\n",
    "            missing = expected - found_dates\n",
    "            if missing:\n",
    "                issues.append({\n",
    "                    \"year\": year,\n",
    "                    \"station\": station,\n",
    "                    \"channel\": ch,\n",
    "                    \"missing_days\": sorted(missing)\n",
    "                })\n",
    "                print(f\"    🚨 Missing {len(missing)} days\")\n",
    "            else:\n",
    "                print(f\"    ✅ Complete\")\n",
    "\n",
    "    if not issues:\n",
    "        print(\"\\n✅ All stations have complete channel coverage for all days.\")\n",
    "    else:\n",
    "        print(\"\\nSummary of Issues:\")\n",
    "        for issue in issues:\n",
    "            print(f\"🚨 {issue['year']} - {issue['station']} - {issue['channel']}: {len(issue['missing_days'])} days missing.\")\n",
    "            print(f\"    Example missing dates: {', '.join(issue['missing_days'][:5])} ...\")\n",
    "\n",
    "validate_waveform_files(root_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d251d0-f42e-4ad4-b003-6a12a1dca328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: 01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_10\n",
      "Processing channel: BHE\n",
      "Processing year: 2020\n",
      "Processing year: 2021\n",
      "Processing year: 2022\n",
      "Processing year: 2023\n",
      "Processing channel: BHN\n",
      "Processing year: 2020\n",
      "Processing year: 2021\n",
      "Processing year: 2022\n",
      "Processing year: 2023\n",
      "Processing channel: BHZ\n",
      "Processing year: 2020\n",
      "Processing year: 2021\n",
      "Processing year: 2022\n",
      "Processing year: 2023\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from obspy import read, Stream\n",
    "\n",
    "# Correct logging configuration\n",
    "logging.shutdown()\n",
    "logging.basicConfig(filename='combine_streams.log', level=logging.INFO, format='%(asctime)s - %(message)s', filemode='w', force=True)\n",
    "\n",
    "def combine_streams(num_days):\n",
    "    \"\"\"\n",
    "    Combines processed daily stream files of the same channel into multi-day streams.\n",
    "    Saves the combined stream files in a folder named \"Combined_Processed_Streams_numberofdays\".\n",
    "    \"\"\"\n",
    "    \n",
    "    base_dir = \"01_Data/01_Seismic_Wave_Data\"\n",
    "    output_dir = os.path.join(base_dir, f\"Combined_Processed_Streams_{num_days}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Created directory: {output_dir}\")\n",
    "\n",
    "    # Define channels (BHE, BHN, BHZ)\n",
    "    channels = [\"BHE\", \"BHN\", \"BHZ\"]\n",
    "    # Define years \n",
    "    years = [\"2020\", \"2021\",\"2022\", \"2023\"]\n",
    "\n",
    "    for channel in channels:\n",
    "        file_list = []\n",
    "        print(f\"Processing channel: {channel}\")\n",
    "\n",
    "        # Collect all processed.mseed files for the channel over all years\n",
    "        for year in years:\n",
    "            print(f\"Processing year: {year}\")\n",
    "            year_dir = os.path.join(base_dir, year)\n",
    "            if os.path.isdir(year_dir):\n",
    "                channel_dir = os.path.join(year_dir, channel)\n",
    "                if os.path.isdir(channel_dir):\n",
    "                    for file in os.listdir(channel_dir):\n",
    "                        if file.endswith(\"_processed.mseed\"):\n",
    "                            file_path = os.path.join(channel_dir, file)\n",
    "                            file_list.append(file_path)\n",
    "\n",
    "        # Sort the file list chronologically\n",
    "        file_list.sort()\n",
    "\n",
    "        # Combine the files in chunks of num_days\n",
    "        for i in range(0, len(file_list), num_days):\n",
    "            group_files = file_list[i:i + num_days]\n",
    "\n",
    "            if len(group_files) == 0:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Read and merge the files with interpolation to fill gaps\n",
    "                combined_stream = Stream()\n",
    "                for file in group_files:\n",
    "                    st = read(file)\n",
    "                    combined_stream += st\n",
    "\n",
    "                # Merge traces using interpolation for gaps\n",
    "                combined_stream.merge(method=1, fill_value='interpolate')\n",
    "\n",
    "                # Determine start and end dates for naming\n",
    "                start_date = os.path.basename(group_files[0]).split('_')[2].split('.')[0]\n",
    "                end_date = os.path.basename(group_files[-1]).split('_')[2].split('.')[0]\n",
    "\n",
    "                # Save the combined stream\n",
    "                output_filename = f\"{channel}_{start_date}_to_{end_date}.mseed\"\n",
    "                output_path = os.path.join(output_dir, output_filename)\n",
    "                combined_stream.write(output_path, format='MSEED')\n",
    "                logging.info(f\"Saved combined stream: {output_filename}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing file group starting with {group_files[0]}: {str(e)}\")\n",
    "\n",
    "# Example usage:\n",
    "combine_streams(10)  # Combine daily processed files into 7-day files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d190f2-0389-48e2-90fb-a4f7eadbbe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: 01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_20\n",
      "\n",
      "Processing 2020  PASC  BHE→ 366 files   (70 window(s) of 20 d, shift 5 d, 1 leftover)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from obspy import read, Stream\n",
    "from typing import Optional\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  CONFIGURE LOGGING (fresh file on every run)\n",
    "# ------------------------------------------------------------------\n",
    "logging.shutdown()\n",
    "logging.basicConfig(\n",
    "    filename=\"combine_streams.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filemode=\"w\",\n",
    "    force=True,\n",
    ")\n",
    "\n",
    "def combine_streams(window_len: int, shift: Optional[int] = None) -> None:\n",
    "    \"\"\"\n",
    "    Combine daily processed *.mseed files into multi-day streams.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    window_len : int\n",
    "        Number of consecutive days to merge per output file.\n",
    "    shift : int, optional\n",
    "        Number of days to advance the window before the next merge.\n",
    "        • shift == window_len  →  non-overlapping windows (default)\n",
    "        • shift  < window_len  →  overlapping / sliding windows\n",
    "        • shift  > window_len  →  gapped windows\n",
    "    \"\"\"\n",
    "    if shift is None:\n",
    "        shift = window_len\n",
    "    if shift <= 0 or window_len <= 0:\n",
    "        raise ValueError(\"`window_len` and `shift` must be positive integers\")\n",
    "\n",
    "    base_dir  = \"01_Data/01_Seismic_Wave_Data\"\n",
    "    channels  = (\"BHE\", \"BHN\", \"BHZ\")\n",
    "    out_dir   = os.path.join(base_dir, f\"Combined_Processed_Streams_{window_len}\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    print(f\"Output directory: {out_dir}\\n\")\n",
    "\n",
    "    for year in sorted(os.listdir(base_dir)):\n",
    "        year_path = os.path.join(base_dir, year)\n",
    "        if not os.path.isdir(year_path):\n",
    "            continue\n",
    "\n",
    "        for station in sorted(os.listdir(year_path)):\n",
    "            station_path = os.path.join(year_path, station)\n",
    "            if not os.path.isdir(station_path):\n",
    "                continue\n",
    "\n",
    "            for channel in channels:\n",
    "                chan_path = os.path.join(station_path, channel)\n",
    "                if not os.path.isdir(chan_path):\n",
    "                    continue      # channel missing for this station-year\n",
    "\n",
    "                # ------------------------------------------------------\n",
    "                #  Gather daily files for this station-year-channel\n",
    "                # ------------------------------------------------------\n",
    "                daily_files = [\n",
    "                    os.path.join(chan_path, f)\n",
    "                    for f in os.listdir(chan_path)\n",
    "                    if f.endswith(\"_processed.mseed\")\n",
    "                ]\n",
    "                daily_files.sort()            # YYYY-MM-DD in name → lexical = chrono\n",
    "                n_files = len(daily_files)\n",
    "                if n_files == 0:\n",
    "                    continue\n",
    "\n",
    "                # ------------------------------------------------------\n",
    "                #  Plan windows (sliding / gapped / non-overlapping)\n",
    "                # ------------------------------------------------------\n",
    "                start_idxs   = range(0, n_files - window_len + 1, shift)\n",
    "                start_idxs_list = list(start_idxs)\n",
    "                n_windows    = len(start_idxs_list)\n",
    "                last_used    = (start_idxs_list[-1] + window_len) if n_windows else 0\n",
    "                leftovers    = n_files - last_used\n",
    "\n",
    "\n",
    "                print(\n",
    "                    f\"Processing {year}  {station}  {channel}\"\n",
    "                    f\"→ {n_files} files   \"\n",
    "                    f\"({n_windows} window(s) of {window_len} d, shift {shift} d, \"\n",
    "                    f\"{leftovers} leftover)\"\n",
    "                )\n",
    "\n",
    "                # ------------------------------------------------------\n",
    "                #  Merge each window\n",
    "                # ------------------------------------------------------\n",
    "                for w, start in enumerate(start_idxs, 1):\n",
    "                    group_files = daily_files[start : start + window_len]\n",
    "                    try:\n",
    "                        st_merged = Stream()\n",
    "                        for fp in group_files:\n",
    "                            st_merged += read(fp)\n",
    "\n",
    "                        st_merged.merge(method=1, fill_value=\"interpolate\")\n",
    "\n",
    "                        first_date = os.path.basename(group_files[0]).split(\"_\")[2]\n",
    "                        last_date  = os.path.basename(group_files[-1]).split(\"_\")[2]\n",
    "\n",
    "                        out_name = (\n",
    "                            f\"{station}_{channel}_{first_date}_to_{last_date}.mseed\"\n",
    "                        )\n",
    "                        st_merged.write(os.path.join(out_dir, out_name), format=\"MSEED\")\n",
    "                        logging.info(\"Saved %s\", out_name)\n",
    "\n",
    "                    except Exception as exc:\n",
    "                        logging.error(\n",
    "                            \"Error combining %s – %s: %s\",\n",
    "                            group_files[0],\n",
    "                            group_files[-1],\n",
    "                            exc,\n",
    "                        )\n",
    "\n",
    "                # ------------------------------------------------------\n",
    "                #  Summary print for this triplet\n",
    "                # ------------------------------------------------------\n",
    "                if n_windows:\n",
    "                    print(\n",
    "                        f\"  ✔  Wrote {n_windows} combined streams; \"\n",
    "                        f\"skipped {leftovers} leftover day(s)\\n\"\n",
    "                    )\n",
    "                else:\n",
    "                    print(\"  ⚠  Not enough data for a single window; nothing saved\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Examples\n",
    "    # combine_streams(window_len=10)            # original behaviour (10-day, no overlap)\n",
    "    # combine_streams(window_len=10, shift=5)   # 10-day windows every 5 days\n",
    "    combine_streams(window_len=20, shift=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79f68d-5533-42c3-950b-a6df1d25a8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: /home/gridsan/mknuth/01_Seismic_Wave_Data_Prediction/01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30_new_2025_07_28\n",
      "\n",
      ".ipynb_checkpoints\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "Processing 2023  AGM  BHE  → 365 files   (48 window(s) of 30 d, shift 7 d, 6 leftover)\n",
      "  ✔  Wrote 48 combined streams; skipped 6 leftover day(s)\n",
      "\n",
      "Processing 2023  AGM  BHN  → 365 files   (48 window(s) of 30 d, shift 7 d, 6 leftover)\n",
      "  ✔  Wrote 48 combined streams; skipped 6 leftover day(s)\n",
      "\n",
      "Processing 2023  AGM  BHZ  → 365 files   (48 window(s) of 30 d, shift 7 d, 6 leftover)\n",
      "  ✔  Wrote 48 combined streams; skipped 6 leftover day(s)\n",
      "\n",
      "Processing 2023  BAI  BHE  → 365 files   (48 window(s) of 30 d, shift 7 d, 6 leftover)\n",
      "  ✔  Wrote 48 combined streams; skipped 6 leftover day(s)\n",
      "\n",
      "Processing 2023  BAI  BHN  → 365 files   (48 window(s) of 30 d, shift 7 d, 6 leftover)\n",
      "  ✔  Wrote 48 combined streams; skipped 6 leftover day(s)\n",
      "\n",
      "Processing 2023  BAI  BHZ  → 365 files   (48 window(s) of 30 d, shift 7 d, 6 leftover)\n",
      "  ✔  Wrote 48 combined streams; skipped 6 leftover day(s)\n",
      "\n",
      "Processing 2023  BHP  BHE  → 365 files   (48 window(s) of 30 d, shift 7 d, 6 leftover)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import logging\n",
    "from obspy import read, Stream, Trace\n",
    "from typing import Optional, Dict\n",
    "import numpy as np\n",
    "\n",
    "def combine_streams(window_len: int, shift: Optional[int] = None) -> None:\n",
    "    \"\"\"\n",
    "    Combine daily processed *.mseed files into multi-day streams.\n",
    "    Creates a single trace spanning the entire window by handling location code\n",
    "    conflicts - ensures all traces have the same location code before merging.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    window_len : int\n",
    "        Number of consecutive days to merge per output file.\n",
    "    shift : int, optional\n",
    "        Number of days to advance the window before the next merge.\n",
    "        • shift == window_len  →  non-overlapping windows (default)\n",
    "        • shift  < window_len  →  overlapping / sliding windows\n",
    "        • shift  > window_len  →  gapped windows\n",
    "    \"\"\"\n",
    "    if shift is None:\n",
    "        shift = window_len\n",
    "    if shift <= 0 or window_len <= 0:\n",
    "        raise ValueError(\"`window_len` and `shift` must be positive integers\")\n",
    "\n",
    "    base_dir  = \"/home/gridsan/mknuth/01_Seismic_Wave_Data_Prediction/01_Data/01_Seismic_Wave_Data\"\n",
    "    channels  = (\"BHE\", \"BHN\", \"BHZ\")\n",
    "    out_dir   = os.path.join(base_dir, f\"Combined_Processed_Streams_{window_len}_new_2025_07_28\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    print(f\"Output directory: {out_dir}\\n\")\n",
    "\n",
    "    for year in sorted(os.listdir(base_dir)):\n",
    "        print(year)\n",
    "        year_path = os.path.join(base_dir, year)\n",
    "        if not os.path.isdir(year_path):\n",
    "            continue\n",
    "\n",
    "        for station in sorted(os.listdir(year_path)):\n",
    "            station_path = os.path.join(year_path, station)\n",
    "            if not os.path.isdir(station_path):\n",
    "                continue\n",
    "\n",
    "            for channel in channels:\n",
    "                chan_path = os.path.join(station_path, channel)\n",
    "                if not os.path.isdir(chan_path):\n",
    "                    continue      # channel missing for this station-year\n",
    "\n",
    "                # ------------------------------------------------------\n",
    "                #  Gather daily files for this station-year-channel\n",
    "                # ------------------------------------------------------\n",
    "                daily_files = [\n",
    "                    os.path.join(chan_path, f)\n",
    "                    for f in os.listdir(chan_path)\n",
    "                    if f.endswith(\"_processed.mseed\")\n",
    "                ]\n",
    "                daily_files.sort()            # YYYY-MM-DD in name → lexical = chrono\n",
    "                n_files = len(daily_files)\n",
    "                if n_files == 0:\n",
    "                    continue\n",
    "\n",
    "                # ------------------------------------------------------\n",
    "                #  Plan windows (sliding / gapped / non-overlapping)\n",
    "                # ------------------------------------------------------\n",
    "                start_idxs   = range(0, n_files - window_len + 1, shift)\n",
    "                n_windows    = len(list(start_idxs))\n",
    "                last_used    = (list(start_idxs)[-1] + window_len) if n_windows else 0\n",
    "                leftovers    = n_files - last_used\n",
    "\n",
    "                print(\n",
    "                    f\"Processing {year}  {station}  {channel}  \"\n",
    "                    f\"→ {n_files} files   \"\n",
    "                    f\"({n_windows} window(s) of {window_len} d, shift {shift} d, \"\n",
    "                    f\"{leftovers} leftover)\"\n",
    "                )\n",
    "\n",
    "                # ------------------------------------------------------\n",
    "                #  Merge each window\n",
    "                # ------------------------------------------------------\n",
    "                for w, start in enumerate(start_idxs, 1):\n",
    "                    group_files = daily_files[start : start + window_len]\n",
    "                    try:\n",
    "                        # First, determine the dominant location code\n",
    "                        loc_count: Dict[str, int] = {}\n",
    "                        all_traces = []\n",
    "                        \n",
    "                        for fp in group_files:\n",
    "                            st = read(fp)\n",
    "                            for tr in st:\n",
    "                                all_traces.append(tr)\n",
    "                                # Handle empty location field (None, empty string, etc.)\n",
    "                                loc = tr.stats.location if tr.stats.location else \"\"\n",
    "                                loc_count[loc] = loc_count.get(loc, 0) + 1\n",
    "                        \n",
    "                        # Find most common location\n",
    "                        if not loc_count:\n",
    "                            raise ValueError(\"No traces found in window files\")\n",
    "                            \n",
    "                        dominant_loc = max(loc_count, key=loc_count.get)\n",
    "                        # Format location for logging - show empty as \"(empty)\"\n",
    "                        display_loc = dominant_loc if dominant_loc else \"(empty)\"\n",
    "                        logging.info(f\"Location counts: {loc_count}, using dominant location: {display_loc}\")\n",
    "                        \n",
    "                        # Set all traces to the dominant location\n",
    "                        st_uniform = Stream()\n",
    "                        for tr in all_traces:\n",
    "                            # Create a new trace with consistent location\n",
    "                            new_tr = Trace(data=tr.data)\n",
    "                            # Copy all stats\n",
    "                            new_tr.stats = tr.stats.copy()\n",
    "                            # Override location with dominant one\n",
    "                            # Empty strings are normalized to empty string\n",
    "                            new_tr.stats.location = dominant_loc if dominant_loc else \"\"\n",
    "                            st_uniform.append(new_tr)\n",
    "                        \n",
    "                        # Now we can merge as usual\n",
    "                        st_merged = st_uniform.merge(method=1, fill_value=\"interpolate\")\n",
    "\n",
    "                        first_date = os.path.basename(group_files[0]).split(\"_\")[2]\n",
    "                        last_date  = os.path.basename(group_files[-1]).split(\"_\")[2]\n",
    "\n",
    "                        out_name = (\n",
    "                            f\"{station}_{channel}_{first_date}_to_{last_date}.mseed\"\n",
    "                        )\n",
    "                        \n",
    "                        st_merged.write(os.path.join(out_dir, out_name), format=\"MSEED\")\n",
    "                        logging.info(\n",
    "                            \"Saved %s (unified location: %s, from %d traces)\", \n",
    "                            out_name, display_loc, len(all_traces)\n",
    "                        )\n",
    "\n",
    "                    except Exception as exc:\n",
    "                        logging.error(\n",
    "                            \"Error combining %s – %s: %s\",\n",
    "                            group_files[0],\n",
    "                            group_files[-1],\n",
    "                            exc,\n",
    "                        )\n",
    "\n",
    "                # ------------------------------------------------------\n",
    "                #  Summary print for this triplet\n",
    "                # ------------------------------------------------------\n",
    "                if n_windows:\n",
    "                    print(\n",
    "                        f\"  ✔  Wrote {n_windows} combined streams; \"\n",
    "                        f\"skipped {leftovers} leftover day(s)\\n\"\n",
    "                    )\n",
    "                else:\n",
    "                    print(\"  ⚠  Not enough data for a single window; nothing saved\\n\")\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "if __name__ == \"__main__\":\n",
    "    # Examples\n",
    "    # combine_streams(window_len=10)            # original behaviour (10-day, no overlap)\n",
    "    # combine_streams(window_len=10, shift=5)   # 10-day windows every 5 days\n",
    "    combine_streams(window_len=30, shift=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14ebdd-f9c4-427e-909a-01dd082a3f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing triplet: BHE_2022-01-01_to_2022-01-30.mseed, BHN_2022-01-01_to_2022-01-30.mseed, BHZ_2022-01-01_to_2022-01-30.mseed\n",
      "Processing triplet: BHE_2022-01-31_to_2022-03-01.mseed, BHN_2022-01-31_to_2022-03-01.mseed, BHZ_2022-01-31_to_2022-03-01.mseed\n",
      "Processing triplet: BHE_2022-03-02_to_2022-03-31.mseed, BHN_2022-03-02_to_2022-03-31.mseed, BHZ_2022-03-02_to_2022-03-31.mseed\n",
      "Processing triplet: BHE_2022-04-01_to_2022-04-30.mseed, BHN_2022-04-01_to_2022-04-30.mseed, BHZ_2022-04-01_to_2022-04-30.mseed\n",
      "Processing triplet: BHE_2022-05-01_to_2022-05-30.mseed, BHN_2022-05-01_to_2022-05-30.mseed, BHZ_2022-05-01_to_2022-05-30.mseed\n",
      "Processing triplet: BHE_2022-05-31_to_2022-06-29.mseed, BHN_2022-05-31_to_2022-06-29.mseed, BHZ_2022-05-31_to_2022-06-29.mseed\n",
      "Processing triplet: BHE_2022-06-30_to_2022-07-29.mseed, BHN_2022-06-30_to_2022-07-29.mseed, BHZ_2022-06-30_to_2022-07-29.mseed\n",
      "Processing triplet: BHE_2022-07-30_to_2022-08-28.mseed, BHN_2022-07-30_to_2022-08-28.mseed, BHZ_2022-07-30_to_2022-08-28.mseed\n",
      "Processing triplet: BHE_2022-08-29_to_2022-09-27.mseed, BHN_2022-08-29_to_2022-09-27.mseed, BHZ_2022-08-29_to_2022-09-27.mseed\n",
      "Processing triplet: BHE_2022-09-28_to_2022-10-27.mseed, BHN_2022-09-28_to_2022-10-27.mseed, BHZ_2022-09-28_to_2022-10-27.mseed\n",
      "Processing triplet: BHE_2022-10-28_to_2022-11-26.mseed, BHN_2022-10-28_to_2022-11-26.mseed, BHZ_2022-10-28_to_2022-11-26.mseed\n",
      "Processing triplet: BHE_2022-11-27_to_2022-12-26.mseed, BHN_2022-11-27_to_2022-12-26.mseed, BHZ_2022-11-27_to_2022-12-26.mseed\n",
      "Processing triplet: BHE_2022-12-27_to_2023-01-25.mseed, BHN_2022-12-27_to_2023-01-25.mseed, BHZ_2022-12-27_to_2023-01-25.mseed\n",
      "Processing triplet: BHE_2023-01-26_to_2023-02-24.mseed, BHN_2023-01-26_to_2023-02-24.mseed, BHZ_2023-01-26_to_2023-02-24.mseed\n",
      "Processing triplet: BHE_2023-02-25_to_2023-03-26.mseed, BHN_2023-02-25_to_2023-03-26.mseed, BHZ_2023-02-25_to_2023-03-26.mseed\n",
      "Processing triplet: BHE_2023-03-27_to_2023-04-25.mseed, BHN_2023-03-27_to_2023-04-25.mseed, BHZ_2023-03-27_to_2023-04-25.mseed\n",
      "Processing triplet: BHE_2023-04-26_to_2023-05-25.mseed, BHN_2023-04-26_to_2023-05-25.mseed, BHZ_2023-04-26_to_2023-05-25.mseed\n",
      "Processing triplet: BHE_2023-05-26_to_2023-06-24.mseed, BHN_2023-05-26_to_2023-06-24.mseed, BHZ_2023-05-26_to_2023-06-24.mseed\n",
      "Processing triplet: BHE_2023-06-25_to_2023-07-24.mseed, BHN_2023-06-25_to_2023-07-24.mseed, BHZ_2023-06-25_to_2023-07-24.mseed\n",
      "Processing triplet: BHE_2023-07-25_to_2023-08-23.mseed, BHN_2023-07-25_to_2023-08-23.mseed, BHZ_2023-07-25_to_2023-08-23.mseed\n",
      "Processing triplet: BHE_2023-08-24_to_2023-09-22.mseed, BHN_2023-08-24_to_2023-09-22.mseed, BHZ_2023-08-24_to_2023-09-22.mseed\n",
      "Processing triplet: BHE_2023-09-23_to_2023-10-22.mseed, BHN_2023-09-23_to_2023-10-22.mseed, BHZ_2023-09-23_to_2023-10-22.mseed\n",
      "Processing triplet: BHE_2023-10-23_to_2023-11-21.mseed, BHN_2023-10-23_to_2023-11-21.mseed, BHZ_2023-10-23_to_2023-11-21.mseed\n",
      "Processing triplet: BHE_2023-11-22_to_2023-12-21.mseed, BHN_2023-11-22_to_2023-12-21.mseed, BHZ_2023-11-22_to_2023-12-21.mseed\n",
      "Processing triplet: BHE_2023-12-22_to_2023-12-31.mseed, BHN_2023-12-22_to_2023-12-31.mseed, BHZ_2023-12-22_to_2023-12-31.mseed\n",
      "Number of training samples: 25\n",
      "Number of training samples: 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2022-01-01_to_2022-01-30.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2022-01-01_to_2022-01-30.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2022-01-01_to_2022-01-30.mseed'],\n",
       "  'label': 4.218933177022274},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2022-01-31_to_2022-03-01.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2022-01-31_to_2022-03-01.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2022-01-31_to_2022-03-01.mseed'],\n",
       "  'label': 4.38305978898007},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2022-03-02_to_2022-03-31.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2022-03-02_to_2022-03-31.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2022-03-02_to_2022-03-31.mseed'],\n",
       "  'label': 4.840269636576788},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2022-04-01_to_2022-04-30.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2022-04-01_to_2022-04-30.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2022-04-01_to_2022-04-30.mseed'],\n",
       "  'label': 4.547186400937867},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2022-05-01_to_2022-05-30.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2022-05-01_to_2022-05-30.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2022-05-01_to_2022-05-30.mseed'],\n",
       "  'label': 3.925849941383353},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2022-05-31_to_2022-06-29.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2022-05-31_to_2022-06-29.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2022-05-31_to_2022-06-29.mseed'],\n",
       "  'label': 4.898886283704572},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2022-06-30_to_2022-07-29.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2022-06-30_to_2022-07-29.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2022-06-30_to_2022-07-29.mseed'],\n",
       "  'label': 4.746483001172333},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2022-07-30_to_2022-08-28.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2022-07-30_to_2022-08-28.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2022-07-30_to_2022-08-28.mseed'],\n",
       "  'label': 4.254103165298945},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2022-08-29_to_2022-09-27.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2022-08-29_to_2022-09-27.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2022-08-29_to_2022-09-27.mseed'],\n",
       "  'label': 3.996189917936694},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2022-09-28_to_2022-10-27.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2022-09-28_to_2022-10-27.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2022-09-28_to_2022-10-27.mseed'],\n",
       "  'label': 5.039566236811255},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2022-10-28_to_2022-11-26.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2022-10-28_to_2022-11-26.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2022-10-28_to_2022-11-26.mseed'],\n",
       "  'label': 4.69},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2022-11-27_to_2022-12-26.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2022-11-27_to_2022-12-26.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2022-11-27_to_2022-12-26.mseed'],\n",
       "  'label': 4.38305978898007},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2022-12-27_to_2023-01-25.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2022-12-27_to_2023-01-25.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2022-12-27_to_2023-01-25.mseed'],\n",
       "  'label': 4.441676436107855},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2023-01-26_to_2023-02-24.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2023-01-26_to_2023-02-24.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2023-01-26_to_2023-02-24.mseed'],\n",
       "  'label': 3.996189917936694},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2023-02-25_to_2023-03-26.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2023-02-25_to_2023-03-26.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2023-02-25_to_2023-03-26.mseed'],\n",
       "  'label': 4.418229777256741},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2023-03-27_to_2023-04-25.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2023-03-27_to_2023-04-25.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2023-03-27_to_2023-04-25.mseed'],\n",
       "  'label': 4.61},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2023-04-26_to_2023-05-25.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2023-04-26_to_2023-05-25.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2023-04-26_to_2023-05-25.mseed'],\n",
       "  'label': 4.136869871043377},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2023-05-26_to_2023-06-24.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2023-05-26_to_2023-06-24.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2023-05-26_to_2023-06-24.mseed'],\n",
       "  'label': 4.887162954279016},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2023-06-25_to_2023-07-24.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2023-06-25_to_2023-07-24.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2023-06-25_to_2023-07-24.mseed'],\n",
       "  'label': 5.485052754982415},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2023-07-25_to_2023-08-23.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2023-07-25_to_2023-08-23.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2023-07-25_to_2023-08-23.mseed'],\n",
       "  'label': 3.738276670574443},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2023-08-24_to_2023-09-22.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2023-08-24_to_2023-09-22.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2023-08-24_to_2023-09-22.mseed'],\n",
       "  'label': 3.71},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2023-09-23_to_2023-10-22.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2023-09-23_to_2023-10-22.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2023-09-23_to_2023-10-22.mseed'],\n",
       "  'label': 4.242379835873387},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2023-10-23_to_2023-11-21.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2023-10-23_to_2023-11-21.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2023-10-23_to_2023-11-21.mseed'],\n",
       "  'label': 5.156799531066823},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2023-11-22_to_2023-12-21.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2023-11-22_to_2023-12-21.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2023-11-22_to_2023-12-21.mseed'],\n",
       "  'label': 4.723036342321219},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHE_2023-12-22_to_2023-12-31.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHN_2023-12-22_to_2023-12-31.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30/BHZ_2023-12-22_to_2023-12-31.mseed'],\n",
       "  'label': 4.723036342321219}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from obspy import read\n",
    "\n",
    "\n",
    "\n",
    "def get_max_magnitude_in_next_30_days(end_date, earthquake_csv):\n",
    "    \"\"\"\n",
    "    Get the maximum earthquake magnitude in the next 30 days.\n",
    "    \"\"\"\n",
    "    future_end_date = end_date + pd.Timedelta(days=30)\n",
    "    df = pd.read_csv(earthquake_csv, parse_dates=[\"Time\"])\n",
    "    mask = (df[\"Time\"] >= end_date) & (df[\"Time\"] <= future_end_date)\n",
    "    future_earthquakes = df[mask]\n",
    "\n",
    "    if future_earthquakes.empty:\n",
    "        return 0.0  # No event found\n",
    "\n",
    "    max_magnitude = future_earthquakes[\"Converted Magnitude\"].max()\n",
    "    return max_magnitude\n",
    "\n",
    "def create_train_dataset(earthquake_csv):\n",
    "    \"\"\"\n",
    "    Precompute the train dataset with file paths and labels.\n",
    "    Returns a list of dictionaries containing file paths and labels.\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "\n",
    "    # Separate lists for each channel\n",
    "    bhe_files = []\n",
    "    bhn_files = []\n",
    "    bhz_files = []\n",
    "\n",
    "    # Access the folder and categorize files\n",
    "    for file_name in os.listdir(combined_stream_dir\n",
    "                               \n",
    "                               \n",
    "                               ):\n",
    "        if file_name.startswith(\"BHE\"):\n",
    "            bhe_files.append(file_name)\n",
    "        elif file_name.startswith(\"BHN\"):\n",
    "            bhn_files.append(file_name)\n",
    "        elif file_name.startswith(\"BHZ\"):\n",
    "            bhz_files.append(file_name)\n",
    "\n",
    "    # Sort each list based on the start date extracted from the filename\n",
    "    # Alphabetically sort the files\n",
    "    bhe_files.sort()\n",
    "    bhn_files.sort()\n",
    "    bhz_files.sort()\n",
    "\n",
    "    # Combine the sorted lists to create triplets\n",
    "    for bhe, bhn, bhz in zip(bhe_files, bhn_files, bhz_files):\n",
    "        try:\n",
    "            # Collect file paths for the current triplet\n",
    "            file_paths = [\n",
    "                os.path.join(combined_stream_dir, bhe),\n",
    "                os.path.join(combined_stream_dir, bhn),\n",
    "                os.path.join(combined_stream_dir, bhz)\n",
    "            ]\n",
    "\n",
    "            # Extract the end date from the filename\n",
    "            end_date_str = bhe[-16:-6]  # Example: '2023-11-26'\n",
    "            end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
    "\n",
    "            # Get the label (maximum magnitude in the next 30 days)\n",
    "            max_magnitude = get_max_magnitude_in_next_30_days(end_date, earthquake_csv)\n",
    "\n",
    "            # Append the file paths and label to the dataset\n",
    "            train_data.append({\n",
    "                \"file_paths\": file_paths,\n",
    "                \"label\": max_magnitude\n",
    "            })\n",
    "\n",
    "            print(f\"Processing triplet: {bhe}, {bhn}, {bhz}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing triplet: {bhe}, {bhn}, {bhz}, Error: {e}\")\n",
    "\n",
    "    print(f\"Number of training samples: {len(train_data)}\")\n",
    "    return train_data\n",
    "\n",
    "\n",
    "# Base directory for combined streams\n",
    "combined_stream_dir = \"/home/gridsan/mknuth/01_Seismic_Wave_Data_Prediction/01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_30_new_2025_07_28\"\n",
    "channels = [\"BHE\", \"BHN\", \"BHZ\"]\n",
    "earthquake_csv = \"/home/gridsan/mknuth/01_Seismic_Wave_Data_Prediction/01_Data/02_Seismic_Event_Data/earthquake_features.parquet\"\n",
    "train_data = create_train_dataset(earthquake_csv)\n",
    "print(f\"Number of training samples: {len(train_data)}\")\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41f01c1b-595d-4dcd-8683-fc3f8afba790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-25 00:00:00\n",
      "2023-10-23 00:00:00\n",
      "2023-12-22 00:00:00\n",
      "2022-10-28 00:00:00\n",
      "2023-04-26 00:00:00\n",
      "2022-01-01 00:00:00\n",
      "2022-03-02 00:00:00\n",
      "2022-08-29 00:00:00\n",
      "2023-08-24 00:00:00\n",
      "2022-12-27 00:00:00\n",
      "2022-06-30 00:00:00\n",
      "2023-06-25 00:00:00\n",
      "2022-05-01 00:00:00\n",
      "2023-10-23 00:00:00\n",
      "2022-01-01 00:00:00\n",
      "2022-03-02 00:00:00\n",
      "2022-10-28 00:00:00\n",
      "2023-08-24 00:00:00\n",
      "2023-06-25 00:00:00\n",
      "2023-02-25 00:00:00\n",
      "2023-12-22 00:00:00\n",
      "2022-06-30 00:00:00\n",
      "2022-08-29 00:00:00\n",
      "2023-04-26 00:00:00\n",
      "2022-05-01 00:00:00\n",
      "2022-12-27 00:00:00\n",
      "2022-03-02 00:00:00\n",
      "2022-10-28 00:00:00\n",
      "2023-10-23 00:00:00\n",
      "2022-05-01 00:00:00\n",
      "2022-01-01 00:00:00\n",
      "2023-08-24 00:00:00\n",
      "2022-06-30 00:00:00\n",
      "2023-06-25 00:00:00\n",
      "2023-02-25 00:00:00\n",
      "2022-12-27 00:00:00\n",
      "2023-12-22 00:00:00\n",
      "2023-04-26 00:00:00\n",
      "2022-08-29 00:00:00\n",
      "13\n",
      "13\n",
      "13\n",
      "Processing triplet: BHE_2022-01-01_to_2022-03-01.mseed, BHN_2022-01-01_to_2022-03-01.mseed, BHZ_2022-01-01_to_2022-03-01.mseed\n",
      "Processing triplet: BHE_2022-03-02_to_2022-04-30.mseed, BHN_2022-03-02_to_2022-04-30.mseed, BHZ_2022-03-02_to_2022-04-30.mseed\n",
      "Processing triplet: BHE_2022-05-01_to_2022-06-29.mseed, BHN_2022-05-01_to_2022-06-29.mseed, BHZ_2022-05-01_to_2022-06-29.mseed\n",
      "Processing triplet: BHE_2022-06-30_to_2022-08-28.mseed, BHN_2022-06-30_to_2022-08-28.mseed, BHZ_2022-06-30_to_2022-08-28.mseed\n",
      "Processing triplet: BHE_2022-08-29_to_2022-10-27.mseed, BHN_2022-08-29_to_2022-10-27.mseed, BHZ_2022-08-29_to_2022-10-27.mseed\n",
      "Processing triplet: BHE_2022-10-28_to_2022-12-26.mseed, BHN_2022-10-28_to_2022-12-26.mseed, BHZ_2022-10-28_to_2022-12-26.mseed\n",
      "Processing triplet: BHE_2022-12-27_to_2023-02-24.mseed, BHN_2022-12-27_to_2023-02-24.mseed, BHZ_2022-12-27_to_2023-02-24.mseed\n",
      "Processing triplet: BHE_2023-02-25_to_2023-04-25.mseed, BHN_2023-02-25_to_2023-04-25.mseed, BHZ_2023-02-25_to_2023-04-25.mseed\n",
      "Processing triplet: BHE_2023-04-26_to_2023-06-24.mseed, BHN_2023-04-26_to_2023-06-24.mseed, BHZ_2023-04-26_to_2023-06-24.mseed\n",
      "Processing triplet: BHE_2023-06-25_to_2023-08-23.mseed, BHN_2023-06-25_to_2023-08-23.mseed, BHZ_2023-06-25_to_2023-08-23.mseed\n",
      "Processing triplet: BHE_2023-08-24_to_2023-10-22.mseed, BHN_2023-08-24_to_2023-10-22.mseed, BHZ_2023-08-24_to_2023-10-22.mseed\n",
      "Processing triplet: BHE_2023-10-23_to_2023-12-21.mseed, BHN_2023-10-23_to_2023-12-21.mseed, BHZ_2023-10-23_to_2023-12-21.mseed\n",
      "Processing triplet: BHE_2023-12-22_to_2023-12-31.mseed, BHN_2023-12-22_to_2023-12-31.mseed, BHZ_2023-12-22_to_2023-12-31.mseed\n",
      "Number of training samples: 13\n",
      "Number of training samples: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHE_2022-01-01_to_2022-03-01.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHN_2022-01-01_to_2022-03-01.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHZ_2022-01-01_to_2022-03-01.mseed'],\n",
       "  'label': 4.38305978898007},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHE_2022-03-02_to_2022-04-30.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHN_2022-03-02_to_2022-04-30.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHZ_2022-03-02_to_2022-04-30.mseed'],\n",
       "  'label': 4.547186400937867},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHE_2022-05-01_to_2022-06-29.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHN_2022-05-01_to_2022-06-29.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHZ_2022-05-01_to_2022-06-29.mseed'],\n",
       "  'label': 4.898886283704572},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHE_2022-06-30_to_2022-08-28.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHN_2022-06-30_to_2022-08-28.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHZ_2022-06-30_to_2022-08-28.mseed'],\n",
       "  'label': 4.254103165298945},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHE_2022-08-29_to_2022-10-27.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHN_2022-08-29_to_2022-10-27.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHZ_2022-08-29_to_2022-10-27.mseed'],\n",
       "  'label': 5.039566236811255},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHE_2022-10-28_to_2022-12-26.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHN_2022-10-28_to_2022-12-26.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHZ_2022-10-28_to_2022-12-26.mseed'],\n",
       "  'label': 4.38305978898007},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHE_2022-12-27_to_2023-02-24.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHN_2022-12-27_to_2023-02-24.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHZ_2022-12-27_to_2023-02-24.mseed'],\n",
       "  'label': 3.996189917936694},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHE_2023-02-25_to_2023-04-25.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHN_2023-02-25_to_2023-04-25.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHZ_2023-02-25_to_2023-04-25.mseed'],\n",
       "  'label': 4.61},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHE_2023-04-26_to_2023-06-24.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHN_2023-04-26_to_2023-06-24.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHZ_2023-04-26_to_2023-06-24.mseed'],\n",
       "  'label': 4.887162954279016},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHE_2023-06-25_to_2023-08-23.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHN_2023-06-25_to_2023-08-23.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHZ_2023-06-25_to_2023-08-23.mseed'],\n",
       "  'label': 3.738276670574443},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHE_2023-08-24_to_2023-10-22.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHN_2023-08-24_to_2023-10-22.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHZ_2023-08-24_to_2023-10-22.mseed'],\n",
       "  'label': 4.242379835873387},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHE_2023-10-23_to_2023-12-21.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHN_2023-10-23_to_2023-12-21.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHZ_2023-10-23_to_2023-12-21.mseed'],\n",
       "  'label': 4.723036342321219},\n",
       " {'file_paths': ['01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHE_2023-12-22_to_2023-12-31.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHN_2023-12-22_to_2023-12-31.mseed',\n",
       "   '01_Data/01_Seismic_Wave_Data/Combined_Processed_Streams_60/BHZ_2023-12-22_to_2023-12-31.mseed'],\n",
       "  'label': 4.723036342321219}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_start_date(filename):\n",
    "    \"\"\"Extract the start date from the file name.\"\"\"\n",
    "    try:\n",
    "        # Example filename: BHE_2022-01-01_to_2022-03-01.mseed\n",
    "        start_date_str = filename.split('_')[1]\n",
    "        start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "        print(start_date)\n",
    "        return start_date\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting date from filename {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_train_dataset(earthquake_csv):\n",
    "    \"\"\"\n",
    "    Precompute the train dataset with file paths and labels.\n",
    "    Returns a list of dictionaries containing file paths and labels.\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "\n",
    "    # Separate lists for each channel\n",
    "    bhe_files = []\n",
    "    bhn_files = []\n",
    "    bhz_files = []\n",
    "\n",
    "    # Access the folder and categorize files\n",
    "    for file_name in os.listdir(combined_stream_dir):\n",
    "        if file_name.startswith(\"BHE\"):\n",
    "            bhe_files.append(file_name)\n",
    "        elif file_name.startswith(\"BHN\"):\n",
    "            bhn_files.append(file_name)\n",
    "        elif file_name.startswith(\"BHZ\"):\n",
    "            bhz_files.append(file_name)\n",
    "\n",
    "    # Sort each list based on the start date extracted from the filename\n",
    "    bhe_files.sort(key=lambda x: extract_start_date(x))\n",
    "    bhn_files.sort(key=lambda x: extract_start_date(x))\n",
    "    bhz_files.sort(key=lambda x: extract_start_date(x))\n",
    "    \n",
    "    print(len(bhe_files))\n",
    "    print(len(bhn_files))\n",
    "    print(len(bhz_files))\n",
    "\n",
    "    # Combine the sorted lists to create triplets\n",
    "    for bhe, bhn, bhz in zip(bhe_files, bhn_files, bhz_files):\n",
    "        try:\n",
    "            # Collect file paths for the current triplet\n",
    "            file_paths = [\n",
    "                os.path.join(combined_stream_dir, bhe),\n",
    "                os.path.join(combined_stream_dir, bhn),\n",
    "                os.path.join(combined_stream_dir, bhz)\n",
    "            ]\n",
    "\n",
    "            # Extract the end date from the filename\n",
    "            end_date_str = bhe[-16:-6]  # Example: '2023-11-26'\n",
    "            end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
    "\n",
    "            # Get the label (maximum magnitude in the next 30 days)\n",
    "            max_magnitude = get_max_magnitude_in_next_30_days(end_date, earthquake_csv)\n",
    "\n",
    "            # Append the file paths and label to the dataset\n",
    "            train_data.append({\n",
    "                \"file_paths\": file_paths,\n",
    "                \"label\": max_magnitude\n",
    "            })\n",
    "\n",
    "            print(f\"Processing triplet: {bhe}, {bhn}, {bhz}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing triplet: {bhe}, {bhn}, {bhz}, Error: {e}\")\n",
    "\n",
    "    print(f\"Number of training samples: {len(train_data)}\")\n",
    "    return train_data\n",
    "\n",
    "earthquake_csv = \"01_Data/02_Seismic_Event_Data/earthquake_event_data_PASC_2020_2024_preprocessed.csv\"\n",
    "train_data = create_train_dataset(earthquake_csv)\n",
    "print(f\"Number of training samples: {len(train_data)}\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4aff28-e20b-4791-a2a5-c253f414dba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (toto_py310)",
   "language": "python",
   "name": "toto_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
